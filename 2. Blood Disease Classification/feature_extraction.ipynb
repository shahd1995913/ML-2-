{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "feature extraction.ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyPeQdpqyUYhrDXfH1WLbosB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shahd1995913/Machine-Learning/blob/main/2.%20Blood%20Disease%20Classification/feature_extraction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Read Data From Kaggle\n",
        "# 2. Split Folder\n",
        "# 3. Preprocessing Data Images\n"
      ],
      "metadata": {
        "id": "7fEnMchX_Lnl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XCYSwtvE-H7M"
      },
      "outputs": [],
      "source": [
        "! pip install kaggle\n",
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json\n",
        "! kaggle competitions download blood-disease-classification-tah\n",
        "! unzip /content/blood-disease-classification-tah.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import copy\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "train_df = pd.read_csv(\"/content/train_set.csv\")\n",
        "test_df = pd.read_csv(\"/content/test_set.csv\")\n",
        "print(train_df['Image'].dtypes)\n",
        "print(train_df['Category'].dtypes)\n",
        "print(train_df['Category'].value_counts())\n",
        "Category = train_df['Category'].value_counts()\n",
        "sns.set(style=\"darkgrid\")\n",
        "sns.barplot(Category.index, Category.values, alpha=.955)\n",
        "plt.title('Frequency Distribution of Category')\n",
        "plt.ylabel('Number of Occurrences', fontsize=12)\n",
        "plt.xlabel('Blood Disease Type', fontsize=12)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "StTZqpoC-KNW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "import imageio\n",
        "import os\n",
        "path = \"/content/Images/Images\"\n",
        "files = os.listdir(path)\n",
        "\n",
        "for index, file in enumerate(files):\n",
        "    os.rename(os.path.join(path, file), os.path.join(path, ''.join([str(index), '.jpg'])))\n",
        "    \n",
        "image_folder_path = \"/content/Images/Images\"\n",
        "\n",
        "onlyfiles = [f for f in listdir(image_folder_path) if isfile(join(image_folder_path, f))]\n",
        "\n",
        "full_filenames = [join(this_image) for this_image in onlyfiles]\n",
        "full_filenames\n",
        " \n",
        "img = pd.DataFrame (full_filenames, columns = ['img number'])"
      ],
      "metadata": {
        "id": "EbW1fOJ7-R1B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# selecting rows based on condition\n",
        "EOSINOPHIL = train_df.loc[train_df['Category'] ==\"EOSINOPHIL\"]\n",
        "print('\\nResult dataframe :\\n', EOSINOPHIL)\n",
        "# selecting rows based on condition\n",
        "MONOCYTE = train_df.loc[train_df['Category'] ==\"MONOCYTE\"]\n",
        "  \n",
        "print('\\nResult dataframe :\\n', MONOCYTE)\n",
        "# selecting rows based on condition\n",
        "LYMPHOCYTE = train_df.loc[train_df['Category'] ==\"LYMPHOCYTE\"]\n",
        "print('\\nResult dataframe :\\n', LYMPHOCYTE)\n",
        "# selecting rows based on condition\n",
        "NEUTROPHIL = train_df.loc[train_df['Category'] ==\"NEUTROPHIL\"]\n",
        "  \n",
        "print('\\nResult dataframe :\\n', NEUTROPHIL)\n",
        "NEUTROPHIL.Image\n",
        "\n",
        "image_folder_path = \"/content/Images/Images\"\n",
        "\n",
        "onlyfiles = [f for f in listdir(image_folder_path) if isfile(join(image_folder_path, f))]\n",
        "\n",
        "full_filenames = [join(this_image) for this_image in onlyfiles]\n",
        "full_filenames"
      ],
      "metadata": {
        "id": "2JSaFUqH-cj-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "c = (NEUTROPHIL.Image ==23)\n",
        "c.value_counts()"
      ],
      "metadata": {
        "id": "HSp9WIFF-ixt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import shutil\n",
        "import os\n",
        "# Create a directory\n",
        "directory = \"NEUTROPHIL_befor_resize\"\n",
        "  \n",
        "# Parent Directory path\n",
        "parent_dir = \"/content/\"\n",
        "  \n",
        "path = os.path.join(parent_dir, directory)\n",
        "  \n",
        "os.mkdir(path)\n",
        "\n",
        "src_dir = \"/content/Images/Images/\"\n",
        "dst_dir = \"/content/NEUTROPHIL_befor_resize/\"\n",
        "for i in listdir(src_dir):\n",
        "  for j in NEUTROPHIL.Image:\n",
        "     if i == str(j)+\".jpg\":\n",
        "          shutil.copy(src_dir+i, dst_dir)"
      ],
      "metadata": {
        "id": "YnirEtDI-lU_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/python\n",
        "from PIL import Image\n",
        "import os, sys\n",
        "\n",
        "directory = \"NEUTROPHIL_After_resize\"\n",
        "  \n",
        "# Parent Directory path\n",
        "parent_dir = \"/content/\"\n",
        "  \n",
        "path = os.path.join(parent_dir, directory)\n",
        "  \n",
        "os.mkdir(path)\n",
        "\n",
        "path = \"/content/NEUTROPHIL_befor_resize/\"\n",
        "dirs = os.listdir( path )\n",
        "save_new_img=\"/content/NEUTROPHIL_After_resize/\"\n",
        "def resize():\n",
        "    for item in dirs:\n",
        "        if os.path.isfile(path+item):\n",
        "            im = Image.open(path+item)\n",
        "            f, e = os.path.splitext(save_new_img+item)\n",
        "            imResize = im.resize((224,224), Image.ANTIALIAS)\n",
        "            imResize.save(f + '.jpg', 'JPEG', quality=90)\n",
        "\n",
        "resize()"
      ],
      "metadata": {
        "id": "WC4BuGTx-o4M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import os, sys\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "directory = \"NEUTROPHIL\"\n",
        "  \n",
        "# Parent Directory path\n",
        "parent_dir = \"/content/\"\n",
        "  \n",
        "path = os.path.join(parent_dir, directory)\n",
        "  \n",
        "os.mkdir(path)\n",
        "path = \"/content/NEUTROPHIL_After_resize/\"\n",
        "dirs = os.listdir( path )\n",
        "save=\"/content/NEUTROPHIL/\"\n",
        "def resize():\n",
        "    for item in dirs:\n",
        "        if os.path.isfile(path+item):\n",
        "            im = Image.open(path+item)\n",
        "            f, e = os.path.splitext(save+item)\n",
        "            img = cv2.imread(path+item)\n",
        "            for gamma in [2.2]:\n",
        "              gamma_corrected = np.array(255*(img / 255) ** gamma, dtype = 'uint8')\n",
        "              cv2.imwrite(f + '.jpg', gamma_corrected)           \n",
        "resize()\n"
      ],
      "metadata": {
        "id": "JhZDnV2f-sfe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a directory\n",
        "directory = \"EOSINOPHIL_befor_resize\"\n",
        "  \n",
        "# Parent Directory path\n",
        "parent_dir = \"/content/\"\n",
        "  \n",
        "path = os.path.join(parent_dir, directory)\n",
        "  \n",
        "os.mkdir(path)\n",
        "\n",
        "src_dir = \"/content/Images/Images/\"\n",
        "dst_dir = \"/content/EOSINOPHIL_befor_resize/\"\n",
        "for i in listdir(src_dir):\n",
        "  for j in EOSINOPHIL.Image:\n",
        "     if i == str(j)+\".jpg\":\n",
        "          shutil.copy(src_dir+i, dst_dir)\n"
      ],
      "metadata": {
        "id": "2k4QLBQE-0SF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/python\n",
        "from PIL import Image\n",
        "import os, sys\n",
        "\n",
        "directory = \"EOSINOPHIL_After_resize\"\n",
        "  \n",
        "# Parent Directory path\n",
        "parent_dir = \"/content/\"\n",
        "  \n",
        "path = os.path.join(parent_dir, directory)\n",
        "  \n",
        "os.mkdir(path)\n",
        "\n",
        "path = \"/content/EOSINOPHIL_befor_resize/\"\n",
        "dirs = os.listdir( path )\n",
        "save_new_img=\"/content/EOSINOPHIL_After_resize/\"\n",
        "def resize():\n",
        "    for item in dirs:\n",
        "        if os.path.isfile(path+item):\n",
        "            im = Image.open(path+item)\n",
        "            f, e = os.path.splitext(save_new_img+item)\n",
        "            imResize = im.resize((224,224), Image.ANTIALIAS)\n",
        "            imResize.save(f + '.jpg', 'JPEG', quality=90)\n",
        "\n",
        "resize()"
      ],
      "metadata": {
        "id": "SpHbR3XE-2P6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "directory = \"EOSINOPHIL\"\n",
        "  \n",
        "# Parent Directory path\n",
        "parent_dir = \"/content/\"\n",
        "  \n",
        "path = os.path.join(parent_dir, directory)\n",
        "  \n",
        "os.mkdir(path)\n",
        "path = \"/content/EOSINOPHIL_After_resize/\"\n",
        "dirs = os.listdir( path )\n",
        "save=\"/content/EOSINOPHIL/\"\n",
        "def resize():\n",
        "    for item in dirs:\n",
        "        if os.path.isfile(path+item):\n",
        "            im = Image.open(path+item)\n",
        "            f, e = os.path.splitext(save+item)\n",
        "            img = cv2.imread(path+item)\n",
        "            for gamma in [2.2]:\n",
        "              gamma_corrected = np.array(255*(img / 255) ** gamma, dtype = 'uint8')\n",
        "              cv2.imwrite(f + '.jpg', gamma_corrected)           \n",
        "resize()"
      ],
      "metadata": {
        "id": "E_1RIbWg-2Zp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a directory\n",
        "directory = \"MONOCYTE_befor_resize\"\n",
        "  \n",
        "# Parent Directory path\n",
        "parent_dir = \"/content/\"\n",
        "  \n",
        "path = os.path.join(parent_dir, directory)\n",
        "  \n",
        "os.mkdir(path)\n",
        "\n",
        "src_dir = \"/content/Images/Images/\"\n",
        "dst_dir = \"/content/MONOCYTE_befor_resize/\"\n",
        "for i in listdir(src_dir):\n",
        "  for j in MONOCYTE.Image:\n",
        "     if i == str(j)+\".jpg\":\n",
        "          shutil.copy(src_dir+i, dst_dir)\n",
        "\n",
        "#!/usr/bin/python\n",
        "from PIL import Image\n",
        "import os, sys\n",
        "\n",
        "directory = \"MONOCYTE_After_resize\"\n",
        "  \n",
        "# Parent Directory path\n",
        "parent_dir = \"/content/\"\n",
        "  \n",
        "path = os.path.join(parent_dir, directory)\n",
        "  \n",
        "os.mkdir(path)\n",
        "\n",
        "path = \"/content/MONOCYTE_befor_resize/\"\n",
        "dirs = os.listdir( path )\n",
        "save_new_img=\"/content/MONOCYTE_After_resize/\"\n",
        "def resize():\n",
        "    for item in dirs:\n",
        "        if os.path.isfile(path+item):\n",
        "            im = Image.open(path+item)\n",
        "            f, e = os.path.splitext(save_new_img+item)\n",
        "            imResize = im.resize((224,224), Image.ANTIALIAS)\n",
        "            imResize.save(f + '.jpg', 'JPEG', quality=90)\n",
        "\n",
        "resize()\n",
        "\n",
        "directory = \"MONOCYTE\"\n",
        "  \n",
        "# Parent Directory path\n",
        "parent_dir = \"/content/\"\n",
        "  \n",
        "path = os.path.join(parent_dir, directory)\n",
        "  \n",
        "os.mkdir(path)\n",
        "path = \"/content/MONOCYTE_After_resize/\"\n",
        "dirs = os.listdir( path )\n",
        "save=\"/content/MONOCYTE/\"\n",
        "def resize():\n",
        "    for item in dirs:\n",
        "        if os.path.isfile(path+item):\n",
        "            im = Image.open(path+item)\n",
        "            f, e = os.path.splitext(save+item)\n",
        "            img = cv2.imread(path+item)\n",
        "            for gamma in [2.2]:\n",
        "              gamma_corrected = np.array(255*(img / 255) ** gamma, dtype = 'uint8')\n",
        "              cv2.imwrite(f + '.jpg', gamma_corrected)           \n",
        "resize()"
      ],
      "metadata": {
        "id": "h9Nqy0GU-7RO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a directory\n",
        "directory = \"LYMPHOCYTE_befor_resize\"\n",
        "  \n",
        "# Parent Directory path\n",
        "parent_dir = \"/content/\"\n",
        "  \n",
        "path = os.path.join(parent_dir, directory)\n",
        "  \n",
        "os.mkdir(path)\n",
        "\n",
        "src_dir = \"/content/Images/Images/\"\n",
        "dst_dir = \"/content/LYMPHOCYTE_befor_resize/\"\n",
        "for i in listdir(src_dir):\n",
        "  for j in LYMPHOCYTE.Image:\n",
        "     if i == str(j)+\".jpg\":\n",
        "          shutil.copy(src_dir+i, dst_dir)\n",
        "\n",
        "#!/usr/bin/python\n",
        "from PIL import Image\n",
        "import os, sys\n",
        "\n",
        "directory = \"LYMPHOCYTE_After_resize\"\n",
        "  \n",
        "# Parent Directory path\n",
        "parent_dir = \"/content/\"\n",
        "  \n",
        "path = os.path.join(parent_dir, directory)\n",
        "  \n",
        "os.mkdir(path)\n",
        "\n",
        "path = \"/content/LYMPHOCYTE_befor_resize/\"\n",
        "dirs = os.listdir( path )\n",
        "save_new_img=\"/content/LYMPHOCYTE_After_resize/\"\n",
        "def resize():\n",
        "    for item in dirs:\n",
        "        if os.path.isfile(path+item):\n",
        "            im = Image.open(path+item)\n",
        "            f, e = os.path.splitext(save_new_img+item)\n",
        "            imResize = im.resize((224,224), Image.ANTIALIAS)\n",
        "            imResize.save(f + '.jpg', 'JPEG', quality=90)\n",
        "\n",
        "resize()\n",
        "\n",
        "directory = \"LYMPHOCYTE\"\n",
        "  \n",
        "# Parent Directory path\n",
        "parent_dir = \"/content/\"\n",
        "  \n",
        "path = os.path.join(parent_dir, directory)\n",
        "  \n",
        "os.mkdir(path)\n",
        "path = \"/content/LYMPHOCYTE_After_resize/\"\n",
        "dirs = os.listdir( path )\n",
        "save=\"/content/LYMPHOCYTE/\"\n",
        "def resize():\n",
        "    for item in dirs:\n",
        "        if os.path.isfile(path+item):\n",
        "            im = Image.open(path+item)\n",
        "            f, e = os.path.splitext(save+item)\n",
        "            img = cv2.imread(path+item)\n",
        "            for gamma in [2.2]:\n",
        "              gamma_corrected = np.array(255*(img / 255) ** gamma, dtype = 'uint8')\n",
        "              cv2.imwrite(f + '.jpg', gamma_corrected)           \n",
        "resize()"
      ],
      "metadata": {
        "id": "9F1Aykw3-9S3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a directory\n",
        "directory = \"test_befor_resize\"\n",
        "  \n",
        "# Parent Directory path\n",
        "parent_dir = \"/content/\"\n",
        "  \n",
        "path = os.path.join(parent_dir, directory)\n",
        "  \n",
        "os.mkdir(path)\n",
        "\n",
        "src_dir = \"/content/Images/Images/\"\n",
        "dst_dir = \"/content/test_befor_resize/\"\n",
        "for i in listdir(src_dir):\n",
        "  for j in test_df.Image:\n",
        "     if i == str(j)+\".jpg\":\n",
        "          shutil.copy(src_dir+i, dst_dir)\n",
        "\n",
        "#!/usr/bin/python\n",
        "from PIL import Image\n",
        "import os, sys\n",
        "\n",
        "directory = \"test_After_resize\"\n",
        "  \n",
        "# Parent Directory path\n",
        "parent_dir = \"/content/\"\n",
        "  \n",
        "path = os.path.join(parent_dir, directory)\n",
        "  \n",
        "os.mkdir(path)\n",
        "\n",
        "path = \"/content/test_befor_resize/\"\n",
        "dirs = os.listdir( path )\n",
        "save_new_img=\"/content/test_After_resize/\"\n",
        "def resize():\n",
        "    for item in dirs:\n",
        "        if os.path.isfile(path+item):\n",
        "            im = Image.open(path+item)\n",
        "            f, e = os.path.splitext(save_new_img+item)\n",
        "            imResize = im.resize((224,224), Image.ANTIALIAS)\n",
        "            imResize.save(f + '.jpg', 'JPEG', quality=90)\n",
        "resize()\n",
        "\n",
        "directory = \"test\"\n",
        "  \n",
        "# Parent Directory path\n",
        "parent_dir = \"/content/\"\n",
        "  \n",
        "path = os.path.join(parent_dir, directory)\n",
        "  \n",
        "os.mkdir(path)\n",
        "path = \"/content/test_After_resize/\"\n",
        "dirs = os.listdir( path )\n",
        "save=\"/content/test/\"\n",
        "def resize():\n",
        "    for item in dirs:\n",
        "        if os.path.isfile(path+item):\n",
        "            im = Image.open(path+item)\n",
        "            f, e = os.path.splitext(save+item)\n",
        "            img = cv2.imread(path+item)\n",
        "            for gamma in [2.2]:\n",
        "              gamma_corrected = np.array(255*(img / 255) ** gamma, dtype = 'uint8')\n",
        "              cv2.imwrite(f + '.jpg', gamma_corrected)           \n",
        "resize()"
      ],
      "metadata": {
        "id": "wLZy5iHF-_Z7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from skimage.feature import greycomatrix, greycoprops\n",
        "from skimage import io\n",
        "import cv2\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import numpy as np\n",
        "import cv2\n",
        "import pandas as pd\n",
        " \n",
        "\n",
        "import pickle\n",
        "from matplotlib import pyplot as plt\n",
        "import os"
      ],
      "metadata": {
        "id": "pVSM2q-VEykz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a directory\n",
        "train = \"train\"\n",
        "testdata = \"testdata\"\n",
        "# Parent Directory path\n",
        "parent_dir = \"/content/\"\n",
        "path = os.path.join(parent_dir, train)\n",
        "path1 = os.path.join(parent_dir, testdata)\n",
        "os.mkdir(path)\n",
        "os.mkdir(path1)\n",
        "\n",
        "# src_dir = \"/content/Images/Images/\"\n",
        "# dst_dir = \"/content/test_befor_resize/\"\n",
        "# for i in listdir(src_dir):\n",
        "#   for j in test_df.Image:\n",
        "#      if i == str(j)+\".jpg\":\n",
        "#           shutil.copy(src_dir+i, dst_dir)\n"
      ],
      "metadata": {
        "id": "71sNQAuJGbgd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a directory\n",
        "LYMPHOCYTE = \"LYMPHOCYTE\"\n",
        "MONOCYTE = \"MONOCYTE\"\n",
        "EOSINOPHIL = \"EOSINOPHIL\"\n",
        "NEUTROPHIL = \"NEUTROPHIL\"\n",
        "# Parent Directory path\n",
        "parent_dir = \"/content/train/\"\n",
        "path3 = os.path.join(parent_dir, LYMPHOCYTE)\n",
        "path4 = os.path.join(parent_dir, MONOCYTE)\n",
        "path5= os.path.join(parent_dir, EOSINOPHIL)\n",
        "path6 = os.path.join(parent_dir, NEUTROPHIL)\n",
        "os.mkdir(path3)\n",
        "os.mkdir(path4)\n",
        "os.mkdir(path5)\n",
        "os.mkdir(path6)"
      ],
      "metadata": {
        "id": "dc22fvXLGbil"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a directory\n",
        "LYMPHOCYTE = \"LYMPHOCYTE\"\n",
        "MONOCYTE = \"MONOCYTE\"\n",
        "EOSINOPHIL = \"EOSINOPHIL\"\n",
        "NEUTROPHIL = \"NEUTROPHIL\"\n",
        "# Parent Directory path\n",
        "parent_dir = \"/content/testdata/\"\n",
        "path3 = os.path.join(parent_dir, LYMPHOCYTE)\n",
        "path4 = os.path.join(parent_dir, MONOCYTE)\n",
        "path5= os.path.join(parent_dir, EOSINOPHIL)\n",
        "path6 = os.path.join(parent_dir, NEUTROPHIL)\n",
        "os.mkdir(path3)\n",
        "os.mkdir(path4)\n",
        "os.mkdir(path5)\n",
        "os.mkdir(path6)"
      ],
      "metadata": {
        "id": "i6J4gSfbGblN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LYMPHOCYTE = train_df.loc[train_df['Category'] ==\"LYMPHOCYTE\"]\n",
        "print('\\nResult dataframe :\\n', LYMPHOCYTE)"
      ],
      "metadata": {
        "id": "SMjCqh5aGbqB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EOSINOPHIL = train_df.loc[train_df['Category'] ==\"EOSINOPHIL\"]\n",
        "print('\\nResult dataframe :\\n', EOSINOPHIL[\"Category\"] )\n",
        "EOSINOPHIL"
      ],
      "metadata": {
        "id": "9gcv6ibkGbv-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "src_dir = \"/content/LYMPHOCYTE/\"\n",
        "dst_dir =\"/content/train/LYMPHOCYTE/\"\n",
        "test_dir=\"/content/testdata/LYMPHOCYTE/\"\n",
        "for i in listdir(src_dir):\n",
        "  for j in LYMPHOCYTE.Image:\n",
        "    if j<=200 and i == str(j)+\".jpg\":\n",
        "      shutil.copy(src_dir+i, test_dir)\n",
        "    elif  j>200 and i == str(j)+\".jpg\":  \n",
        "          shutil.copy(src_dir+i, dst_dir)"
      ],
      "metadata": {
        "id": "KcSnyw6yGbnp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "src_dir = \"/content/EOSINOPHIL/\"\n",
        "dst_dir =\"/content/train/EOSINOPHIL/\"\n",
        "test_dir=\"/content/testdata/EOSINOPHIL/\"\n",
        "for i in listdir(src_dir):\n",
        "  for j in EOSINOPHIL.Image:\n",
        "    if j<=200 and i == str(j)+\".jpg\":\n",
        "      shutil.copy(src_dir+i, test_dir)\n",
        "    elif  j>200 and i == str(j)+\".jpg\":  \n",
        "          shutil.copy(src_dir+i, dst_dir)"
      ],
      "metadata": {
        "id": "NB1fII4LGbsk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "MONOCYTE = train_df.loc[train_df['Category'] ==\"MONOCYTE\"]\n",
        "print('\\nResult dataframe :\\n', MONOCYTE[\"Category\"] )\n",
        "MONOCYTE"
      ],
      "metadata": {
        "id": "MxRyyn12NtL9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "src_dir = \"/content/MONOCYTE/\"\n",
        "dst_dir =\"/content/train/MONOCYTE/\"\n",
        "test_dir=\"/content/testdata/MONOCYTE/\"\n",
        "for i in listdir(src_dir):\n",
        "  for j in MONOCYTE.Image:\n",
        "    if j<=200 and i == str(j)+\".jpg\":\n",
        "      shutil.copy(src_dir+i, test_dir)\n",
        "    elif  j>200 and i == str(j)+\".jpg\":  \n",
        "          shutil.copy(src_dir+i, dst_dir)"
      ],
      "metadata": {
        "id": "qbOmsMC1OHXk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "NEUTROPHIL = train_df.loc[train_df['Category'] ==\"NEUTROPHIL\"]\n",
        "print('\\nResult dataframe :\\n', NEUTROPHIL[\"Category\"] )\n",
        "NEUTROPHIL\n",
        "src_dir = \"/content/NEUTROPHIL/\"\n",
        "dst_dir =\"/content/train/NEUTROPHIL/\"\n",
        "test_dir=\"/content/testdata/NEUTROPHIL/\"\n",
        "for i in listdir(src_dir):\n",
        "  for j in NEUTROPHIL.Image:\n",
        "    if j<=200 and i == str(j)+\".jpg\":\n",
        "      shutil.copy(src_dir+i, test_dir)\n",
        "    elif  j>200 and i == str(j)+\".jpg\":  \n",
        "          shutil.copy(src_dir+i, dst_dir)"
      ],
      "metadata": {
        "id": "UXI-V17sOHiI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np \n",
        "import matplotlib.pyplot as plt\n",
        "import glob\n",
        "import cv2\n",
        "import os\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "from skimage.filters import sobel\n",
        "from skimage.feature import greycomatrix, greycoprops\n",
        "from skimage.measure import shannon_entropy\n",
        "\n",
        "#Resize images to\n",
        "SIZE = 128\n",
        "\n",
        "#Capture images and labels into arrays.\n",
        "#Start by creating empty lists.\n",
        "train_images = []\n",
        "train_labels = [] \n",
        "#for directory_path in glob.glob(\"cell_images/train/*\"):\n",
        "for directory_path in glob.glob(\"/content/train/*\"):\n",
        "    label = directory_path.split(\"\\\\\")[-1]\n",
        "    print(label)\n",
        "    for img_path in glob.glob(os.path.join(directory_path, \"*.jpg\")):\n",
        "        print(img_path)\n",
        "        img = cv2.imread(img_path, 0) #Reading color images\n",
        "        img = cv2.resize(img, (SIZE, SIZE)) #Resize images\n",
        "        train_images.append(img)\n",
        "        train_labels.append(label)\n",
        "        "
      ],
      "metadata": {
        "id": "dFAGX41GOHkJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_images = np.array(train_images)\n",
        "train_labels = np.array(train_labels)\n",
        "\n",
        "#Do exactly the same for test/validation images\n",
        "# test\n",
        "test_images = []\n",
        "test_labels = []\n",
        "#for directory_path in glob.glob(\"cell_images/test/*\"): \n",
        "for directory_path in glob.glob(\"/content/testdata/*\"):\n",
        "    fruit_label = directory_path.split(\"\\\\\")[-1]\n",
        "    for img_path in glob.glob(os.path.join(directory_path, \"*.jpg\")):\n",
        "        img = cv2.imread(img_path, 0)\n",
        "        img = cv2.resize(img, (SIZE, SIZE))\n",
        "        test_images.append(img)\n",
        "        test_labels.append(fruit_label)\n",
        "        \n",
        "test_images = np.array(test_images)\n",
        "test_labels = np.array(test_labels)"
      ],
      "metadata": {
        "id": "G-B9c5ZYOHmj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Encode labels from text (folder names) to integers."
      ],
      "metadata": {
        "id": "M7FH0WK_PrcW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn import preprocessing\n",
        "le = preprocessing.LabelEncoder()\n",
        "le.fit(test_labels)\n",
        "test_labels_encoded = le.transform(test_labels)\n",
        "le.fit(train_labels)\n",
        "train_labels_encoded = le.transform(train_labels)\n",
        "\n",
        "#Split data into test and train datasets (already split but assigning to meaningful convention)\n",
        "#If you only have one dataset then split here\n",
        "x_train, y_train, x_test, y_test = train_images, train_labels_encoded, test_images, test_labels_encoded"
      ],
      "metadata": {
        "id": "9BIikk0oOHo6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###################################################################\n",
        "# FEATURE EXTRACTOR function\n",
        "# input shape is (n, x, y, c) - number of images, x, y, and channels\n",
        "def feature_extractor(dataset):\n",
        "    image_dataset = pd.DataFrame()\n",
        "    for image in range(dataset.shape[0]):  #iterate through each file         \n",
        "        df = pd.DataFrame()  #Temporary data frame to capture information for each loop.\n",
        "        #Reset dataframe to blank after each loop.\n",
        "        \n",
        "        img = dataset[image, :,:]\n",
        "    ################################################################\n",
        "    #START ADDING DATA TO THE DATAFRAME\n",
        "  \n",
        "                \n",
        "         #Full image\n",
        "        #GLCM = greycomatrix(img, [1], [0, np.pi/4, np.pi/2, 3*np.pi/4])\n",
        "        GLCM = greycomatrix(img, [1], [0])       \n",
        "        GLCM_Energy = greycoprops(GLCM, 'energy')[0]\n",
        "        df['Energy'] = GLCM_Energy\n",
        "        GLCM_corr = greycoprops(GLCM, 'correlation')[0]\n",
        "        df['Corr'] = GLCM_corr       \n",
        "        GLCM_diss = greycoprops(GLCM, 'dissimilarity')[0]\n",
        "        df['Diss_sim'] = GLCM_diss       \n",
        "        GLCM_hom = greycoprops(GLCM, 'homogeneity')[0]\n",
        "        df['Homogen'] = GLCM_hom       \n",
        "        GLCM_contr = greycoprops(GLCM, 'contrast')[0]\n",
        "        df['Contrast'] = GLCM_contr\n",
        "\n",
        "\n",
        "        GLCM2 = greycomatrix(img, [3], [0])       \n",
        "        GLCM_Energy2 = greycoprops(GLCM2, 'energy')[0]\n",
        "        df['Energy2'] = GLCM_Energy2\n",
        "        GLCM_corr2 = greycoprops(GLCM2, 'correlation')[0]\n",
        "        df['Corr2'] = GLCM_corr2       \n",
        "        GLCM_diss2 = greycoprops(GLCM2, 'dissimilarity')[0]\n",
        "        df['Diss_sim2'] = GLCM_diss2       \n",
        "        GLCM_hom2 = greycoprops(GLCM2, 'homogeneity')[0]\n",
        "        df['Homogen2'] = GLCM_hom2       \n",
        "        GLCM_contr2 = greycoprops(GLCM2, 'contrast')[0]\n",
        "        df['Contrast2'] = GLCM_contr2\n",
        "\n",
        "        GLCM3 = greycomatrix(img, [5], [0])       \n",
        "        GLCM_Energy3 = greycoprops(GLCM3, 'energy')[0]\n",
        "        df['Energy3'] = GLCM_Energy3\n",
        "        GLCM_corr3 = greycoprops(GLCM3, 'correlation')[0]\n",
        "        df['Corr3'] = GLCM_corr3       \n",
        "        GLCM_diss3 = greycoprops(GLCM3, 'dissimilarity')[0]\n",
        "        df['Diss_sim3'] = GLCM_diss3       \n",
        "        GLCM_hom3 = greycoprops(GLCM3, 'homogeneity')[0]\n",
        "        df['Homogen3'] = GLCM_hom3       \n",
        "        GLCM_contr3 = greycoprops(GLCM3, 'contrast')[0]\n",
        "        df['Contrast3'] = GLCM_contr3\n",
        "\n",
        "        GLCM4 = greycomatrix(img, [0], [np.pi/4])       \n",
        "        GLCM_Energy4 = greycoprops(GLCM4, 'energy')[0]\n",
        "        df['Energy4'] = GLCM_Energy4\n",
        "        GLCM_corr4 = greycoprops(GLCM4, 'correlation')[0]\n",
        "        df['Corr4'] = GLCM_corr4       \n",
        "        GLCM_diss4 = greycoprops(GLCM4, 'dissimilarity')[0]\n",
        "        df['Diss_sim4'] = GLCM_diss4       \n",
        "        GLCM_hom4 = greycoprops(GLCM4, 'homogeneity')[0]\n",
        "        df['Homogen4'] = GLCM_hom4       \n",
        "        GLCM_contr4 = greycoprops(GLCM4, 'contrast')[0]\n",
        "        df['Contrast4'] = GLCM_contr4\n",
        "        \n",
        "        GLCM5 = greycomatrix(img, [0], [np.pi/2])       \n",
        "        GLCM_Energy5 = greycoprops(GLCM5, 'energy')[0]\n",
        "        df['Energy5'] = GLCM_Energy5\n",
        "        GLCM_corr5 = greycoprops(GLCM5, 'correlation')[0]\n",
        "        df['Corr5'] = GLCM_corr5       \n",
        "        GLCM_diss5 = greycoprops(GLCM5, 'dissimilarity')[0]\n",
        "        df['Diss_sim5'] = GLCM_diss5       \n",
        "        GLCM_hom5 = greycoprops(GLCM5, 'homogeneity')[0]\n",
        "        df['Homogen5'] = GLCM_hom5       \n",
        "        GLCM_contr5 = greycoprops(GLCM5, 'contrast')[0]\n",
        "        df['Contrast5'] = GLCM_contr5\n",
        "        \n",
        "        #Add more filters as needed\n",
        "        #entropy = shannon_entropy(img)\n",
        "        #df['Entropy'] = entropy\n",
        "\n",
        "        \n",
        "        #Append features from current image to the dataset\n",
        "        image_dataset = image_dataset.append(df)\n",
        "        \n",
        "    return image_dataset\n",
        "####################################################################"
      ],
      "metadata": {
        "id": "l54kxV3xOHsc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Extract features from training images\n",
        "image_features = feature_extractor(x_train)\n",
        "X_for_ML =image_features\n"
      ],
      "metadata": {
        "id": "bvN8M62WQFr9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Reshape to a vector for Random Forest / SVM training\n",
        "n_features = image_features.shape[1]\n",
        "image_features = np.expand_dims(image_features, axis=0)\n",
        "X_for_ML = np.reshape(image_features, (x_train.shape[0], -1))  #Reshape to #images, features\n",
        "\n",
        "#Define the classifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "RF_model = RandomForestClassifier(n_estimators = 50, random_state = 42)\n",
        "\n",
        "#Can also use SVM but RF is faster and may be more accurate.\n",
        "from sklearn import svm\n",
        "SVM_model = svm.SVC(decision_function_shape='ovo')  #For multiclass classification\n",
        "SVM_model.fit(X_for_ML, y_train)\n",
        "\n",
        "# Fit the model on training data\n",
        "RF_model.fit(X_for_ML, y_train) #For sklearn no one hot encoding"
      ],
      "metadata": {
        "id": "H156PO6cRrgD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Predict on Test data\n",
        "#Extract features from test data and reshape, just like training data\n",
        "test_features = feature_extractor(x_test)\n",
        "test_features = np.expand_dims(test_features, axis=0)\n",
        "test_for_RF = np.reshape(test_features, (x_test.shape[0], -1))\n"
      ],
      "metadata": {
        "id": "hmt3MBQVQFxb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Predict on test\n",
        "test_prediction = RF_model.predict(test_for_RF)\n",
        "test_prediction=np.argmax(test_prediction, axis=1)\n",
        "# #Inverse le transform to get original label back. \n",
        "# test_prediction = le.inverse_transform(test_prediction)\n",
        "y_true = np.argmax(testdata, axis=0).\n",
        "\n",
        "\n",
        "# from sklearn import preprocessing\n",
        "# le = preprocessing.LabelEncoder()\n",
        "# le.fit(test_labels)\n",
        "# test_labels_encoded = le.transform(test_labels)\n",
        "\n",
        "\n",
        "#Split data into test and train datasets (already split but assigning to meaningful convention)\n",
        "#If you only have one dataset then split here\n",
        "# x_train, y_train, x_test, y_test = train_images, train_labels_encoded, test_images, test_labels_encoded"
      ],
      "metadata": {
        "id": "AYLKj0geVQh4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "test_prediction\n",
        "test_labels"
      ],
      "metadata": {
        "id": "i0_jdcDJUQlu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Print overall accuracy\n",
        "from sklearn import metrics\n",
        "print (\"Accuracy = \", metrics.accuracy_score(test_labels, test_prediction))\n",
        "\n",
        "#Print confusion matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(test_labels, test_prediction)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(6,6))         # Sample figsize in inches\n",
        "sns.set(font_scale=1.6)\n",
        "sns.heatmap(cm, annot=True, linewidths=.5, ax=ax)\n",
        "\n",
        "#Check results on a few random images\n",
        "import random\n",
        "n=random.randint(0, x_test.shape[0]-1) #Select the index of image to be loaded for testing\n",
        "img = x_test[n]\n",
        "plt.imshow(img)"
      ],
      "metadata": {
        "id": "JT4jMrEmQF0M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np \n",
        "import matplotlib.pyplot as plt\n",
        "import glob\n",
        "import cv2\n",
        "import os\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "from skimage.filters import sobel\n",
        "from skimage.feature import greycomatrix, greycoprops\n",
        "from skimage.measure import shannon_entropy\n",
        "\n",
        "\n",
        "#Resize images to\n",
        "SIZE = 128\n",
        "\n",
        "#Capture images and labels into arrays.\n",
        "#Start by creating empty lists.\n",
        "train_images = []\n",
        "train_labels = []\n",
        "#Capture images and labels into arrays.\n",
        "#Start by creating empty lists.\n",
        "train_images = []\n",
        "train_labels = [] \n",
        "#for directory_path in glob.glob(\"cell_images/train/*\"):\n",
        "for directory_path in glob.glob(\"/content/train/*\"):\n",
        "    label = directory_path.split(\"\\\\\")[-1]\n",
        "    print(label)\n",
        "    for img_path in glob.glob(os.path.join(directory_path, \"*.jpg\")):\n",
        "        print(img_path)\n",
        "        img = cv2.imread(img_path, 0) #Reading color images\n",
        "        img = cv2.resize(img, (SIZE, SIZE)) #Resize images\n",
        "        train_images.append(img)\n",
        "        train_labels.append(label)\n",
        "        \n",
        "train_images = np.array(train_images)\n",
        "train_labels = np.array(train_labels)\n",
        "#Do exactly the same for test/validation images\n",
        "# test\n",
        "test_images = []\n",
        "test_labels = []\n",
        "#for directory_path in glob.glob(\"cell_images/test/*\"): \n",
        "for directory_path in glob.glob(\"/content/testdata/*\"):\n",
        "    fruit_label = directory_path.split(\"\\\\\")[-1]\n",
        "    for img_path in glob.glob(os.path.join(directory_path, \"*.jpg\")):\n",
        "        img = cv2.imread(img_path, 0)\n",
        "        img = cv2.resize(img, (SIZE, SIZE))\n",
        "        test_images.append(img)\n",
        "        test_labels.append(fruit_label)\n",
        "        \n",
        "test_images = np.array(test_images)\n",
        "test_labels = np.array(test_labels)\n",
        "#Encode labels from text (folder names) to integers.\n",
        "from sklearn import preprocessing\n",
        "le = preprocessing.LabelEncoder()\n",
        "le.fit(test_labels)\n",
        "test_labels_encoded = le.transform(test_labels)\n",
        "le.fit(train_labels)\n",
        "train_labels_encoded = le.transform(train_labels)\n",
        "#Split data into test and train datasets (already split but assigning to meaningful convention)\n",
        "#If you only have one dataset then split here\n",
        "x_train, y_train, x_test, y_test = train_images, train_labels_encoded, test_images, test_labels_encoded\n",
        "###################################################################\n",
        "# FEATURE EXTRACTOR function\n",
        "# input shape is (n, x, y, c) - number of images, x, y, and channels\n",
        "def feature_extractor(dataset):\n",
        "    image_dataset = pd.DataFrame()\n",
        "    for image in range(dataset.shape[0]):  #iterate through each file \n",
        "        #print(image)\n",
        "        \n",
        "        df = pd.DataFrame()  #Temporary data frame to capture information for each loop.\n",
        "        #Reset dataframe to blank after each loop.\n",
        "        \n",
        "        img = dataset[image, :,:]\n",
        "    ################################################################\n",
        "    #START ADDING DATA TO THE DATAFRAME\n",
        "  \n",
        "                \n",
        "         #Full image\n",
        "        #GLCM = greycomatrix(img, [1], [0, np.pi/4, np.pi/2, 3*np.pi/4])\n",
        "        GLCM = greycomatrix(img, [1], [0])       \n",
        "        GLCM_Energy = greycoprops(GLCM, 'energy')[0]\n",
        "        df['Energy'] = GLCM_Energy\n",
        "        GLCM_corr = greycoprops(GLCM, 'correlation')[0]\n",
        "        df['Corr'] = GLCM_corr       \n",
        "        GLCM_diss = greycoprops(GLCM, 'dissimilarity')[0]\n",
        "        df['Diss_sim'] = GLCM_diss       \n",
        "        GLCM_hom = greycoprops(GLCM, 'homogeneity')[0]\n",
        "        df['Homogen'] = GLCM_hom       \n",
        "        GLCM_contr = greycoprops(GLCM, 'contrast')[0]\n",
        "        df['Contrast'] = GLCM_contr\n",
        "\n",
        "\n",
        "        GLCM2 = greycomatrix(img, [3], [0])       \n",
        "        GLCM_Energy2 = greycoprops(GLCM2, 'energy')[0]\n",
        "        df['Energy2'] = GLCM_Energy2\n",
        "        GLCM_corr2 = greycoprops(GLCM2, 'correlation')[0]\n",
        "        df['Corr2'] = GLCM_corr2       \n",
        "        GLCM_diss2 = greycoprops(GLCM2, 'dissimilarity')[0]\n",
        "        df['Diss_sim2'] = GLCM_diss2       \n",
        "        GLCM_hom2 = greycoprops(GLCM2, 'homogeneity')[0]\n",
        "        df['Homogen2'] = GLCM_hom2       \n",
        "        GLCM_contr2 = greycoprops(GLCM2, 'contrast')[0]\n",
        "        df['Contrast2'] = GLCM_contr2\n",
        "\n",
        "        GLCM3 = greycomatrix(img, [5], [0])       \n",
        "        GLCM_Energy3 = greycoprops(GLCM3, 'energy')[0]\n",
        "        df['Energy3'] = GLCM_Energy3\n",
        "        GLCM_corr3 = greycoprops(GLCM3, 'correlation')[0]\n",
        "        df['Corr3'] = GLCM_corr3       \n",
        "        GLCM_diss3 = greycoprops(GLCM3, 'dissimilarity')[0]\n",
        "        df['Diss_sim3'] = GLCM_diss3       \n",
        "        GLCM_hom3 = greycoprops(GLCM3, 'homogeneity')[0]\n",
        "        df['Homogen3'] = GLCM_hom3       \n",
        "        GLCM_contr3 = greycoprops(GLCM3, 'contrast')[0]\n",
        "        df['Contrast3'] = GLCM_contr3\n",
        "\n",
        "        GLCM4 = greycomatrix(img, [0], [np.pi/4])       \n",
        "        GLCM_Energy4 = greycoprops(GLCM4, 'energy')[0]\n",
        "        df['Energy4'] = GLCM_Energy4\n",
        "        GLCM_corr4 = greycoprops(GLCM4, 'correlation')[0]\n",
        "        df['Corr4'] = GLCM_corr4       \n",
        "        GLCM_diss4 = greycoprops(GLCM4, 'dissimilarity')[0]\n",
        "        df['Diss_sim4'] = GLCM_diss4       \n",
        "        GLCM_hom4 = greycoprops(GLCM4, 'homogeneity')[0]\n",
        "        df['Homogen4'] = GLCM_hom4       \n",
        "        GLCM_contr4 = greycoprops(GLCM4, 'contrast')[0]\n",
        "        df['Contrast4'] = GLCM_contr4\n",
        "        \n",
        "        GLCM5 = greycomatrix(img, [0], [np.pi/2])       \n",
        "        GLCM_Energy5 = greycoprops(GLCM5, 'energy')[0]\n",
        "        df['Energy5'] = GLCM_Energy5\n",
        "        GLCM_corr5 = greycoprops(GLCM5, 'correlation')[0]\n",
        "        df['Corr5'] = GLCM_corr5       \n",
        "        GLCM_diss5 = greycoprops(GLCM5, 'dissimilarity')[0]\n",
        "        df['Diss_sim5'] = GLCM_diss5       \n",
        "        GLCM_hom5 = greycoprops(GLCM5, 'homogeneity')[0]\n",
        "        df['Homogen5'] = GLCM_hom5       \n",
        "        GLCM_contr5 = greycoprops(GLCM5, 'contrast')[0]\n",
        "        df['Contrast5'] = GLCM_contr5\n",
        "        \n",
        "        #Add more filters as needed\n",
        "        #entropy = shannon_entropy(img)\n",
        "        #df['Entropy'] = entropy\n",
        "\n",
        "        \n",
        "        #Append features from current image to the dataset\n",
        "        image_dataset = image_dataset.append(df)\n",
        "        \n",
        "    return image_dataset\n",
        "####################################################################\n",
        "#Extract features from training images\n",
        "image_features = feature_extractor(x_train)\n",
        "X_for_ML =image_features\n",
        "#Reshape to a vector for Random Forest / SVM training\n",
        "n_features = image_features.shape[1]\n",
        "image_features = np.expand_dims(image_features, axis=0)\n",
        "X_for_ML = np.reshape(image_features, (x_train.shape[0], -1))  #Reshape to #images, features\n",
        "\n",
        "#Define the classifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "RF_model = RandomForestClassifier(n_estimators = 50, random_state = 42)\n",
        "\n",
        "#Can also use SVM but RF is faster and may be more accurate.\n",
        "from sklearn import svm\n",
        "SVM_model = svm.SVC(decision_function_shape='ovo')  #For multiclass classification\n",
        "SVM_model.fit(X_for_ML, y_train)\n",
        "\n",
        "#Fit the model on training data\n",
        "RF_model.fit(X_for_ML, y_train) #For sklearn no one hot encoding\n",
        "import lightgbm as lgb\n",
        " #Class names for LGBM start at 0 so reassigning labels from 1,2,3,4 to 0,1,2,3\n",
        "d_train = lgb.Dataset(X_for_ML, label=y_train)\n",
        "\n",
        "# https://lightgbm.readthedocs.io/en/latest/Parameters.html\n",
        "lgbm_params = {'learning_rate':0.05, 'boosting_type':'dart',    \n",
        "              'objective':'multiclass',\n",
        "              'metric': 'multi_logloss',\n",
        "              'num_leaves':100,\n",
        "              'max_depth':10,\n",
        "              'num_class':4}  #no.of unique values in the target class not inclusive of the end value"
      ],
      "metadata": {
        "id": "6C6JnVvrQF2t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lgb_model = lgb.train(lgbm_params, d_train, 100) #50 iterations. Increase iterations for small learning rates\n",
        "#Predict on Test data\n",
        "#Extract features from test data and reshape, just like training data\n",
        "test_features = feature_extractor(x_test)\n",
        "test_features = np.expand_dims(test_features, axis=0)\n",
        "test_for_RF = np.reshape(test_features, (x_test.shape[0], -1))\n",
        "\n",
        "#Predict on test\n",
        "test_prediction = lgb_model.predict(test_for_RF)\n",
        "test_prediction=np.argmax(test_prediction, axis=1)\n",
        "#Inverse le transform to get original label back. \n",
        "test_prediction = le.inverse_transform(test_prediction)"
      ],
      "metadata": {
        "id": "hjnbsAy7WWB-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Print overall accuracy\n",
        "from sklearn import metrics\n",
        "print (\"Accuracy = \", metrics.accuracy_score(test_labels, test_prediction))\n",
        "#Print confusion matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(test_labels, test_prediction)"
      ],
      "metadata": {
        "id": "LKkobiR0QF5V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_prediction == test_labels"
      ],
      "metadata": {
        "id": "Bn8_1OntW1Ts"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_labels"
      ],
      "metadata": {
        "id": "tCEb95QTQF8y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}