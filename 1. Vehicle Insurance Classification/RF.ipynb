{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RF.ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyMqxlTDeYpe5ysn6y20zWEe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shahd1995913/ML-2-/blob/main/RF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load libraries\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import train_test_split # Import train_test_split function\n",
        "from sklearn import metrics #Import scikit-learn metrics module for accuracy calculation\n",
        "\n",
        "#Import Random Forest Model\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "pima = pd.read_csv(\"/content/newtrain_data.csv\")\n",
        "\n",
        "del pima[\"index\"]"
      ],
      "metadata": {
        "id": "1egxG2VIhurL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pima"
      ],
      "metadata": {
        "id": "ez57wG17hzFe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(pima[\"Response\"].value_counts())\n",
        "\n",
        "pima.groupby('Response').size().plot(kind='pie',\n",
        "                                       y = \"Response\",\n",
        "                                       label = \"Type\",\n",
        "                                       autopct='%1.1f%%')"
      ],
      "metadata": {
        "id": "u2CALKghiKam"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "zeron = pima[pima[\"Response\"] == 0]\n",
        "one  = pima[pima[\"Response\"] == 1]\n",
        "print(zeron.shape)\n",
        "print(one.shape)"
      ],
      "metadata": {
        "id": "VMwF2BnAiUwl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Upsampling with sklearn"
      ],
      "metadata": {
        "id": "uknGIyxriwiD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils import resample\n",
        "zeron_upsample = resample(one,\n",
        "             replace=True,\n",
        "             n_samples=len(zeron),\n",
        "             random_state=42)\n",
        "\n",
        "print(zeron_upsample.shape)"
      ],
      "metadata": {
        "id": "EB-CiP_Wix5Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_upsampled = pd.concat([zeron, zeron_upsample])\n",
        "\n",
        "print(data_upsampled[\"Response\"].value_counts())\n",
        "\n",
        "data_upsampled.groupby('Response').size().plot(kind='pie',\n",
        "                                       y = \"Response\",\n",
        "                                       label = \"Type\",\n",
        "                                       autopct='%1.1f%%')"
      ],
      "metadata": {
        "id": "uBCJRaVfjFW5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "zeron = data_upsampled[data_upsampled[\"Response\"] == 0]\n",
        "one  = data_upsampled[data_upsampled[\"Response\"] == 1]\n",
        "print(zeron.shape)\n",
        "print(one.shape)"
      ],
      "metadata": {
        "id": "MRSINUQQlG_U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9xKtligwOu1t"
      },
      "outputs": [],
      "source": [
        "#split dataset in features and target variable\n",
        "feature_cols = ['Gender',\t'Age',\t'Driving_License',\t'Region_Code',\t'Previously_Insured',\t'Vehicle_Age',\t'Vehicle_Damage',\t'Annual_Premium'\t,'Policy_Sales_Channel',\t'Vintage']\n",
        "X = data_upsampled[feature_cols] # Features\n",
        "y = data_upsampled.Response # Target variable\n",
        "\n",
        "# Split dataset into training set and test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1) # 70% training and 30% test"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize the data\n",
        "# from sklearn.preprocessing import MinMaxScaler\n",
        "# # # creating a scaler\n",
        "# mm = MinMaxScaler()\n",
        "#  # feeding the independent variable into the scaler\n",
        "# X_train = mm.fit_transform(X_train)\n",
        "# X_test = mm.transform(X_test)"
      ],
      "metadata": {
        "id": "-ZN9PMFLzW82"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a Gaussian Classifier\n",
        "clf=RandomForestClassifier(n_estimators=100)\n",
        "\n",
        "#Train the model using the training sets y_pred=clf.predict(X_test)\n",
        "clf.fit(X_train,y_train)\n",
        "\n",
        "y_pred=clf.predict(X_test)"
      ],
      "metadata": {
        "id": "kikqQhZhzicC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Import scikit-learn metrics module for accuracy calculation\n",
        "from sklearn import metrics\n",
        "# Model Accuracy, how often is the classifier correct?\n",
        "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
      ],
      "metadata": {
        "id": "NJSEb4f0PUec"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import recall_score , precision_score , roc_auc_score ,roc_curve\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(\"Accuracy on Test -->:\", metrics.accuracy_score(y_test, y_pred))\n",
        "# print(custom_model_score)\n",
        "print(classification_report(y_test,y_pred))"
      ],
      "metadata": {
        "id": "G-jWZxxxPiEU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/test_set.csv\")"
      ],
      "metadata": {
        "id": "RuRltEDotOkx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "33o4KlPAtOnc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#convert 'team' column to numeric\n",
        "df['Gender'] = pd.factorize(df['Gender'])[0]\n",
        "df['Vehicle_Damage'] = pd.factorize(df['Vehicle_Damage'])[0]\n",
        "df['Vehicle_Age'] = pd.factorize(df['Vehicle_Age'])[0]\n",
        "#view updated DataFrame\n",
        "df['Vehicle_Age'].unique()\n",
        "df['Gender'].unique()\n",
        "df['Vehicle_Damage'].unique()"
      ],
      "metadata": {
        "id": "uqCr4dEatOqS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# deleting a column\n",
        "# del df['id']\n",
        "display(\"DataFrame after deletion\")\n",
        "display(df)"
      ],
      "metadata": {
        "id": "4lSz04CTtOs3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop rows with Nan values\n",
        "df = df.dropna() # removes rows with any NaN values\n",
        "df = df.reset_index() # reset's row indexes in case any rows were dropped\n",
        "df.head()"
      ],
      "metadata": {
        "id": "cFdS6_-0ttMx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape\n",
        "del df[\"index\"]\n"
      ],
      "metadata": {
        "id": "iwQL15ydttVk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "qVvw5E16ttYA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features = df.drop(['id'],axis = 1)"
      ],
      "metadata": {
        "id": "NfjsT3y2ttbl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred = clf.predict(features)"
      ],
      "metadata": {
        "id": "rtXxKGmKtOvY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s = pd.DataFrame(pred)"
      ],
      "metadata": {
        "id": "fgEQBMYHtOx3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "idd = df[['id']]"
      ],
      "metadata": {
        "id": "-3xNP82RtO05"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "idd['Response'] = s"
      ],
      "metadata": {
        "id": "CY-zSh4utO4F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s.value_counts()"
      ],
      "metadata": {
        "id": "yzQC_-knu0qP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "idd.to_csv('submission3.csv', index=False)"
      ],
      "metadata": {
        "id": "5U2HNY1huyBQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}